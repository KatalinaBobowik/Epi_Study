---
title: 4.IndoSamples_EffectOfSequencingDepth.R
author: katalinabobowik
date: '2020-09-13'

---

Last updated: `r Sys.Date()`
Code version: `r system("git log -1 --format=oneline | cut -d' ' -f1", intern = TRUE)`


```{r setup, include=FALSE}
# created by KSB, 20.01.19
# Script created to inspect where reads are mapping to. 

# load packages
require(ggplot2)
require(RColorBrewer)
library(dplyr)
library(plyr)
library(phyloseq)
library(reshape2)
library(ggpubr)
library(vegan)
library(metacoder)

# set ggplot colour theme to white
theme_set(theme_bw())

# set up directories
inputdir = "/Users/katalinabobowik/Documents/UniMelb_PhD/Analysis/UniMelb_Sumba/ReferenceFiles/EpiStudy/"
AllReadsdir = "/Users/katalinabobowik/Documents/UniMelb_PhD/Analysis/UniMelb_Sumba/Output/Epi_Study/All_Reads/"
Indo250Kdir = "/Users/katalinabobowik/Documents/UniMelb_PhD/Analysis/UniMelb_Sumba/Output/Epi_Study/Indo_250K/"
outputdir = "/Users/katalinabobowik/Documents/UniMelb_PhD/Analysis/UniMelb_Sumba/Output/Epi_Study/Rarefaction_Singletons/"

```

## Data processing

Talk about what weve done 

Talk about problem... 

The first thing we need to do is to load in our subsmapled data from CCMetagen.
We have this for counts and for RPM data

Here is the rough break down of the number of sequences obtained:

*  ~250 million raw reads
*  ~150 million reads with unique molecular identifier
*  ~114 million reads mapped to genome or controls

```{r}
subSampled_250K_Indo_RPM <- read.csv(paste0(inputdir,"RPM_Indo_SubSampled_250K.csv"),check.names=FALSE)
```

We then need to convert this to a PhyloSeq object, which is a micorbiome package 
which will help us with all of our stuff.

```{r}
taxa_raw <- as.matrix(subSampled_250K_Indo_RPM[,c("Superkingdom","Kingdom","Phylum", "Class", "Order","Family","Genus","Species")])
abund_raw <- as.matrix(subSampled_250K_Indo_RPM[,-which(colnames(subSampled_250K_Indo_RPM) %in% c("Superkingdom","Kingdom","Phylum", "Class", "Order","Family","Genus","Species"))])

# convert to Phyloseq object
tax = tax_table(taxa_raw)
taxa = otu_table(abund_raw, taxa_are_rows = TRUE)
subSampled_250K_Indo_RPM_physeq = phyloseq(taxa, tax)
```

Phyloseq objects allow you to add in information on samples. Here,
well get information on the sample name and the island of the individual.

```{r}
# add in sample information, starting with Island
samplenames <- colnames(otu_table(subSampled_250K_Indo_RPM_physeq))
island <- sapply(strsplit(samplenames, "[-.]"), `[`, 1)
# make this into a df and add to the Phloseq object
samples_df=data.frame(SampleName=colnames(otu_table(subSampled_250K_Indo_RPM_physeq)), SamplePop=island)
samples = sample_data(samples_df)
rownames(samples)=samples$SampleName
sample_data(subSampled_250K_Indo_RPM_physeq) <- samples
```

Many of the things well be doing below require count data, so we can process this in the same way as the
RPM data


```{r}
subSampled_250K_Indo_Counts <- read.csv(paste0(inputdir,"Indo_noFiltering_Subsampled_Counts.csv"),check.names=FALSE)
taxa_raw <- as.matrix(subSampled_250K_Indo_Counts[,c("Superkingdom","Kingdom","Phylum", "Class", "Order","Family","Genus","Species")])
abund_raw <- as.matrix(subSampled_250K_Indo_Counts[,-which(colnames(subSampled_250K_Indo_Counts) %in% c("Superkingdom","Kingdom","Phylum", "Class", "Order","Family","Genus","Species"))])

# convert to Phyloseq object
tax = tax_table(taxa_raw)
taxa = otu_table(abund_raw, taxa_are_rows = TRUE)
subSampled_250K_Indo_Counts_physeq = phyloseq(taxa, tax)
# add in sample information, starting with Island
samplenames <- colnames(otu_table(subSampled_250K_Indo_Counts_physeq))
island <- sapply(strsplit(samplenames, "[-.]"), `[`, 1)
# make this into a df and add to the Phloseq object
samples_df=data.frame(SampleName=colnames(otu_table(subSampled_250K_Indo_Counts_physeq)), SamplePop=island)
samples = sample_data(samples_df)
rownames(samples)=samples$SampleName
sample_data(subSampled_250K_Indo_Counts_physeq) <- samples
```

Make sure counts and RPM phyloseq objects are the same

```{r}
subSampled_250K_Indo_RPM_physeq
subSampled_250K_Indo_Counts_physeq
```

They are! 

Removing low-abundance counts

The easiest way to get rid of some error in your data is to throw out any count information below some threshold. 
The threshold is up to you; removing singletons or doubletons is common.

We can look at the effect of removing singletons by rarefaction curves.

Created by creating random order of which the individuals in the community are picked. 
Used for two purposes: 1) estimating how many species are in the community (we hardly ever record all species in an environment. The way we can estimate the total number of species in a community is by extrapolating that curve. The curve can be described by a mathematical function and it has an asymptote. Asymptote is  the estimate of the total number o f species in that community. 
2. determine how extensively we have sampled the species in the community. We do this by looking at the shape of the rarefaction curve. If the curve has not started to flatten off, we have not captured everything. 

We need to show this in counts because...

Lets see how they look at 1 and at 5. 

```{r, figures-side, fig.show="hold", out.width="50%", message=FALSE}
# Separate species' abundances and taxonomy columns
subSamp_250K <- otu_table(subSampled_250K_Indo_Counts_physeq)

# Try out different filtering methods:
for (i in c(1,5)){
	subSamp_250K[subSamp_250K<=i]<-0
	rarecurve(t(otu_table(subSamp_250K, taxa_are_rows = TRUE)), step=20, label=T, xlab="Counts",ylab="Number Species",main=paste("Removing Reads",i,"And Below",sep=" "))
}
```

You can see that the asymptote in the curve is much farther when more reads are removed.

This is beacuse you need more reads to detect rare species.

Because our starting read depth is small, we will stick with singletons.

## Comparing subsampled data to allreads
we need to know the effect of subsampling our data.

One thing we can do is to check the rarefaction curves again to see the threshold at which all reads
can pick things up.

We first need  to load in the all reads count data. 

```{r}
allReads_Counts <- read.csv(paste0(inputdir,"Indo_AllReads_Counts.csv"),check.names=FALSE)
taxa_raw <- as.matrix(allReads_Counts[,c("Superkingdom","Kingdom","Phylum", "Class", "Order","Family","Genus","Species")])
abund_raw <- as.matrix(allReads_Counts[,-which(colnames(allReads_Counts) %in% c("Superkingdom","Kingdom","Phylum", "Class", "Order","Family","Genus","Species"))])

# convert to Phyloseq object
tax = tax_table(taxa_raw)
taxa = otu_table(abund_raw, taxa_are_rows = TRUE)
allReads_Counts_physeq = phyloseq(taxa, tax)
# add in sample information, starting with Island
samplenames <- colnames(otu_table(allReads_Counts_physeq))
island <- sapply(strsplit(samplenames, "[-.]"), `[`, 1)
# make this into a df and add to the Phloseq object
samples_df=data.frame(SampleName=colnames(otu_table(allReads_Counts_physeq)), SamplePop=island)
samples = sample_data(samples_df)
rownames(samples)=samples$SampleName
sample_data(allReads_Counts_physeq) <- samples
allReads_Counts_physeq
```

now lets compare it to the allreads data.

```{r, figures-side-allreads, fig.show="hold", out.width="50%", message=FALSE}
allReads <- otu_table(allReads_Counts_physeq)

for (i in c(1,5)){
	allReads[allReads<=i]<-0
	rarecurve(t(otu_table(allReads, taxa_are_rows = TRUE)), step=20, label=T, xlab="Counts",ylab="Number Species", main=paste("Removing Reads",i,"And Below",sep=" "))
}
```
Barplot of unmapped reads raw library size numbers.

We have a big range of unmapped reads library sizes. bigger library sizes will affect 
our ability to detect rare taxa.

We can see that having a larger sample size increases your ability to detect taxa- so 
when removing singletons, we can pick up 15 taxa at the asymptote max as opposed to 5.
However this is expected- the reason we downsampled is because having a larger library depth
allows for the identification of more taxa. But, the good thing is that the trends we see conytinue-
SMP-PTB028 and MPI-025 are two samples with the highest diversity, where most of the other samples
have low diversity. Furthermore, 
#######

a=read.table("/Users/katalinabobowik/Documents/UniMelb_PhD/Analysis/UniMelb_Sumba/Output/Epi_Study/QC/allReads_AllStages_Ordered.txt", header=T, sep="\t")
preSubSample=a[,1:4]
preSubSample=preSubSample[match(preSubSample$Samples,names(SeqDepth)),]
# match row order
preSubSample=preSubSample[match(names(SeqDepth),preSubSample$Samples),]
SeqDepth = colSums(otu_table(allReads))
plot(preSubSample$Unmapped, SeqDepth)
text(preSubSample$Unmapped, SeqDepth, preSubSample$Samples, cex=0.6, pos=4, col="red") 

# do this with number of OTUs
nOTUs = colSums(otu_table(allReads)!=0)
plot(preSubSample$Unmapped, nOTUs)
text(preSubSample$Unmapped, nOTUs, preSubSample$Samples, cex=0.6, pos=4, col="red") 

nOTUs2 = colSums(otu_table(subSamp_250K)!=0)
SeqDepth2 = colSums(otu_table(subSamp_250K))

